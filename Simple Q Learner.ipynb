{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Q Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-20 18:17:08,802] Making new env: Taxi-v2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Taxi-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: 500\tActions: 6\n"
     ]
    }
   ],
   "source": [
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "print(f'States: {n_states:,}\\tActions: {n_actions:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initializing the Q-matrix\n",
    "Q = np.zeros(shape=[n_states, n_actions])\n",
    "# Learning rate\n",
    "lr = 0.1\n",
    "# Discount factor\n",
    "y = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 10,000\tTotal reward: -200Transitions: 200"
     ]
    }
   ],
   "source": [
    "# how many episodes\n",
    "episodes = 10000\n",
    "# number of times an agent performs a transition\n",
    "transitions = []\n",
    "# all total rewards\n",
    "rewards = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    n_transition = 0\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        n_transition += 1\n",
    "        action = np.argmax(Q[state])\n",
    "        state1, reward, done, _ = env.step(action)\n",
    "        # Update Q value\n",
    "        Q[state, action] += lr * (reward + y * np.max(Q[state1]) - Q[state, action])\n",
    "        total_reward += reward\n",
    "    # Record all transitions and rewards collected\n",
    "    transitions.append(n_transition)\n",
    "    rewards.append(total_reward)\n",
    "    sys.stdout.write(f'\\rEpisode: {episode+1:,}\\tTotal reward: {total_reward:,}\\t'\n",
    "                     f'Transitions: {n_transition:,}')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum »»» Transitions: 200\tReward: -200\n",
      "Minimum »»» Transitions: 200\tReward: -236\n"
     ]
    }
   ],
   "source": [
    "# maximum transitions & reward\n",
    "max_transition = max(transitions)\n",
    "max_reward = max(rewards)\n",
    "# minimum transitions & reward\n",
    "min_transition = min(transitions)\n",
    "min_reward = min(rewards)\n",
    "print(f'Maximum »»» Transitions: {max_transition:,}\\tReward: {max_reward:,}')\n",
    "print(f'Minimum »»» Transitions: {min_transition:,}\\tReward: {min_reward:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward at max transition: -218\n",
      "Reward at min transition: -218\n"
     ]
    }
   ],
   "source": [
    "# Reward @ maximum transition\n",
    "reward_max_trans = rewards[transitions.index(max_transition)]\n",
    "# Reward @ minimum transition\n",
    "reward_min_trans = rewards[transitions.index(min_transition)]\n",
    "print(f'Reward at max transition: {reward_max_trans:,}')\n",
    "print(f'Reward at min transition: {reward_min_trans:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition at max reward: 200\n",
      "Transition at min reward: 200\n"
     ]
    }
   ],
   "source": [
    "# Transition @ maximum reward\n",
    "trans_max_reward = transitions[rewards.index(max_reward)]\n",
    "# Transition @ minimum reward\n",
    "trans_min_reward = transitions[rewards.index(min_reward)]\n",
    "print(f'Transition at max reward: {trans_max_reward:,}')\n",
    "print(f'Transition at min reward: {trans_min_reward:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
